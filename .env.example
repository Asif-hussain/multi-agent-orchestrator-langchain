# ============================================
# REQUIRED API KEYS
# ============================================

# OpenRouter API Key (REQUIRED)
# Get your free API key from: https://openrouter.ai/keys
# This is used for all LLM and embedding model calls
OPENROUTER_API_KEY=sk-or-v1-your-key-here

# Langfuse API Keys (REQUIRED for observability/tracing)
# Get free API keys from: https://cloud.langfuse.com → Settings → API Keys
# Used for tracing, monitoring, and evaluation scoring
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key-here
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key-here
LANGFUSE_HOST=https://cloud.langfuse.com

# ============================================
# OPTIONAL: MODEL CONFIGURATION
# ============================================
# All models below have sensible defaults. Only change if you want to:
# - Use different models for cost/quality tradeoffs
# - Experiment with different providers (OpenAI, Anthropic, etc.)
# - Optimize performance for your specific use case

# Embedding Model (for vector search and document retrieval)
# Default: openai/text-embedding-3-small (cost-effective, good quality)
# Recommendations:
#   - openai/text-embedding-3-small: Best cost/performance ratio
#   - openai/text-embedding-3-large: Higher quality, 2x cost
# Cost: ~$0.0001 per 1000 tokens (small), ~$0.0003 per 1000 tokens (large)
EMBEDDING_MODEL=openai/text-embedding-3-small

# LLM Model (for answer generation and query classification)
# Default: gpt-3.5-turbo (fast, affordable, good quality)
# You can specify with or without "openai/" prefix (auto-normalized)
# Recommendations by use case:
#   - Production (cost-optimized): gpt-3.5-turbo
#   - Production (quality-optimized): gpt-4o-mini or gpt-4-turbo
#   - Development/Testing: gpt-3.5-turbo
#   - Alternative providers: anthropic/claude-3-haiku, anthropic/claude-3-sonnet
# Cost estimates per 1M tokens (input/output):
#   - gpt-3.5-turbo: $0.50/$1.50
#   - gpt-4o-mini: $0.15/$0.60
#   - gpt-4-turbo: $10/$30
#   - anthropic/claude-3-haiku: $0.25/$1.25
LLM_MODEL=gpt-3.5-turbo

# Evaluator Model (for response quality assessment - BONUS feature)
# Default: gpt-3.5-turbo (same as LLM_MODEL)
# This model evaluates the quality of responses on multiple dimensions
# Recommendations:
#   - Use same as LLM_MODEL for consistency
#   - Use gpt-4 variants for more accurate evaluation
# Note: Evaluation adds extra API calls, consider cost implications
EVALUATOR_MODEL=gpt-3.5-turbo

# ============================================
# OPTIONAL: OPENROUTER CONFIGURATION
# ============================================
# OpenRouter base URL (only change if using custom endpoint)
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# ============================================
# OPTIONAL: RAG CONFIGURATION
# ============================================
# Document Chunking - How documents are split for retrieval
# Larger chunks = more context but less precise retrieval
# Smaller chunks = more precise but may miss context

# Size of each document chunk in characters
# Default: 1000 (good balance for most use cases)
# Recommendations: 500-2000 depending on document structure
CHUNK_SIZE=1000

# Overlap between consecutive chunks in characters
# Default: 200 (maintains context between chunks)
# Recommendations: 10-20% of CHUNK_SIZE
CHUNK_OVERLAP=200

# Number of document chunks to retrieve per query
# Default: 4 (provides good context without token overflow)
# Recommendations: 3-6 depending on chunk size and model context window
RETRIEVAL_K=4

# ============================================
# OPTIONAL: MODEL PARAMETERS
# ============================================
# Model Temperature - Controls response randomness
# Default: 0.1 (low temperature for factual, deterministic responses)
# Range: 0.0 (deterministic) to 2.0 (very creative/random)
# Recommendations:
#   - Support/FAQ systems: 0.0-0.2 (factual, consistent)
#   - Creative writing: 0.7-1.2 (varied, creative)
#   - Brainstorming: 1.0-2.0 (highly creative)
TEMPERATURE=0.1

# ============================================
# OPTIONAL: LOGGING CONFIGURATION
# ============================================
# Python logging level for agent operations
# Default: INFO (shows important operations)
# Options:
#   - DEBUG: Detailed debugging information
#   - INFO: General informational messages
#   - WARNING: Warning messages only
#   - ERROR: Error messages only
#   - CRITICAL: Critical errors only
LOG_LEVEL=INFO
