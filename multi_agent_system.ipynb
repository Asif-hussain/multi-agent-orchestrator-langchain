{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Customer Support Routing System\n",
    "\n",
    "This notebook implements an intelligent customer support system that:\n",
    "- Automatically classifies incoming queries by department\n",
    "- Routes queries to specialized RAG agents\n",
    "- Provides accurate answers grounded in company documentation\n",
    "- Maintains full observability with Langfuse tracing\n",
    "- Evaluates response quality automatically\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "User Query ‚Üí Orchestrator (Classification) ‚Üí Specialized Agent (RAG) ‚Üí Response\n",
    "                                            ‚Üì\n",
    "                                    Evaluator (Quality Check)\n",
    "                                            ‚Üì\n",
    "                                    Langfuse (Observability)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "\n",
    "First, let's import all necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "# Langfuse imports\n",
    "from langfuse import Langfuse\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# Our custom agents\n",
    "from src.agents import (\n",
    "    HRAgent,\n",
    "    TechAgent,\n",
    "    FinanceAgent,\n",
    "    OrchestratorAgent,\n",
    "    EvaluatorAgent\n",
    ")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded successfully!\n",
      "   OpenRouter API Key: sk-or-v1...\n",
      "   Langfuse Public Key: pk-lf-9cace04a-...\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API keys are set\n",
    "assert os.getenv(\"OPENROUTER_API_KEY\"), \"OPENROUTER_API_KEY not found in environment variables\"\n",
    "assert os.getenv(\"LANGFUSE_PUBLIC_KEY\"), \"LANGFUSE_PUBLIC_KEY not found in environment variables\"\n",
    "assert os.getenv(\"LANGFUSE_SECRET_KEY\"), \"LANGFUSE_SECRET_KEY not found in environment variables\"\n",
    "\n",
    "print(\"‚úÖ Environment variables loaded successfully!\")\n",
    "print(f\"   OpenRouter API Key: {os.getenv('OPENROUTER_API_KEY')[:8]}...\")\n",
    "print(f\"   Langfuse Public Key: {os.getenv('LANGFUSE_PUBLIC_KEY')[:15]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Loading & Vector Stores\n",
    "\n",
    "We'll load company documentation for each department and create vector stores for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Document directories:\n",
      "   HR docs: 4 files\n",
      "   Tech docs: 3 files\n",
      "   Finance docs: 4 files\n",
      "\n",
      "‚úÖ Document directories verified!\n"
     ]
    }
   ],
   "source": [
    "# Verify document directories exist\n",
    "data_dir = Path(\"data\")\n",
    "hr_docs = data_dir / \"hr_docs\"\n",
    "tech_docs = data_dir / \"tech_docs\"\n",
    "finance_docs = data_dir / \"finance_docs\"\n",
    "\n",
    "print(\"üìÅ Document directories:\")\n",
    "print(f\"   HR docs: {len(list(hr_docs.glob('*.txt')))} files\")\n",
    "print(f\"   Tech docs: {len(list(tech_docs.glob('*.txt')))} files\")\n",
    "print(f\"   Finance docs: {len(list(finance_docs.glob('*.txt')))} files\")\n",
    "print(\"\\n‚úÖ Document directories verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Langfuse for Observability\n",
    "\n",
    "Langfuse provides complete tracing and monitoring of our multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Langfuse initialized!\n",
      "   You can view traces at: https://cloud.langfuse.com\n"
     ]
    }
   ],
   "source": [
    "# Initialize Langfuse client\n",
    "langfuse = Langfuse(\n",
    "    public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    host=os.getenv(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\")\n",
    ")\n",
    "\n",
    "# Create callback handler for tracing\n",
    "# Note: In newer langfuse.langchain, the CallbackHandler uses the global Langfuse client\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Langfuse initialized!\")\n",
    "print(\"   You can view traces at: https://cloud.langfuse.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Specialized RAG Agents\n",
    "\n",
    "Each agent specializes in a specific domain (HR, IT, Finance) with its own documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing HR Agent...\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Initializing HR Agent...\")\n",
    "hr_agent = HRAgent(langfuse_handler=langfuse_handler)\n",
    "hr_agent.initialize(docs_path=\"data/hr_docs\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Tech/IT Agent...\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Initializing Tech/IT Agent...\")\n",
    "tech_agent = TechAgent(langfuse_handler=langfuse_handler)\n",
    "tech_agent.initialize(docs_path=\"data/tech_docs\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Finance Agent...\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Initializing Finance Agent...\")\n",
    "finance_agent = FinanceAgent(langfuse_handler=langfuse_handler)\n",
    "finance_agent.initialize(docs_path=\"data/finance_docs\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Orchestrator Agent\n",
    "\n",
    "The orchestrator classifies queries and routes them to the appropriate specialized agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Initializing Orchestrator Agent...\n",
      "\n",
      "‚úÖ Orchestrator ready!\n",
      "   Can route queries to: HR, IT, Finance\n"
     ]
    }
   ],
   "source": [
    "print(\"üéØ Initializing Orchestrator Agent...\")\n",
    "orchestrator = OrchestratorAgent(\n",
    "    hr_agent=hr_agent,\n",
    "    tech_agent=tech_agent,\n",
    "    finance_agent=finance_agent,\n",
    "    langfuse_handler=langfuse_handler\n",
    ")\n",
    "print(\"\\n‚úÖ Orchestrator ready!\")\n",
    "print(\"   Can route queries to: HR, IT, Finance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Evaluator Agent (BONUS)\n",
    "\n",
    "The evaluator assesses response quality on multiple dimensions and logs scores to Langfuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚≠ê Initializing Evaluator Agent (BONUS)...\n",
      "\n",
      "‚úÖ Evaluator ready!\n",
      "   Will evaluate responses on: Relevance, Completeness, Accuracy, Clarity\n"
     ]
    }
   ],
   "source": [
    "print(\"‚≠ê Initializing Evaluator Agent (BONUS)...\")\n",
    "evaluator = EvaluatorAgent(langfuse_client=langfuse)\n",
    "print(\"\\n‚úÖ Evaluator ready!\")\n",
    "print(\"   Will evaluate responses on: Relevance, Completeness, Accuracy, Clarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing with Sample Queries\n",
    "\n",
    "Let's test the system with queries from different departments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: HR Query - Paid Time Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROCESSING QUERY: How many PTO days do I get per year?\n",
      "================================================================================\n",
      "\n",
      "[Orchestrator] Classifying query: How many PTO days do I get per year?\n",
      "[Orchestrator] Classified as: HR (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to employee benefits and leave policies, which fall under the HR department's responsibilities.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CLASSIFICATION:\n",
      "  Department: HR\n",
      "  Confidence: 0.90\n",
      "  Reasoning: The query is related to employee benefits and leave policies, which fall under the HR department's responsibilities.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ANSWER:\n",
      "Based on the information provided in the context, full-time employees accrue PTO as follows:\n",
      "- 0-2 years of service: 15 days (120 hours) per year\n",
      "- 3-5 years of service: 20 days (160 hours) per year\n",
      "- 6-10 years of service: 25 days (200 hours) per year\n",
      "- 10+ years of service: 30 days (240 hours) per year\n",
      "\n",
      "Part-time employees accrue PTO on a pro-rated basis. PTO accrues at a rate of 1.25 days per month. \n",
      "\n",
      "If you have any specific questions about your PTO accrual based on your years of service or start date, I recommend contacting the HR department at hr@company.com or ext. 4200 for further clarification.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1 = \"How many PTO days do I get per year?\"\n",
    "result1 = orchestrator.process_query(query1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: IT Query - Laptop Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROCESSING QUERY: My laptop won't turn on, what should I do?\n",
      "================================================================================\n",
      "\n",
      "[Orchestrator] Classifying query: My laptop won't turn on, what should I do?\n",
      "[Orchestrator] Classified as: IT (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to hardware troubleshooting, which falls under the IT department's responsibilities.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CLASSIFICATION:\n",
      "  Department: IT\n",
      "  Confidence: 0.90\n",
      "  Reasoning: The query is related to hardware troubleshooting, which falls under the IT department's responsibilities.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ANSWER:\n",
      "If your laptop won't turn on, follow these steps:\n",
      "\n",
      "1. Check that the power adapter is securely connected to both the laptop and the power outlet.\n",
      "2. Try plugging the power adapter into a different power outlet to rule out any issues with the current outlet.\n",
      "3. Hold down the power button for 10 seconds to perform a hard reset.\n",
      "4. If the laptop still does not turn on, contact IT Support for further assistance.\n",
      "5. If the issue is critical and you need to continue working, inquire about loaner laptops that may be available for temporary use.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"My laptop won't turn on, what should I do?\"\n",
    "result2 = orchestrator.process_query(query2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Finance Query - Expense Reimbursement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROCESSING QUERY: What is the reimbursement policy for business travel expenses?\n",
      "================================================================================\n",
      "\n",
      "[Orchestrator] Classifying query: What is the reimbursement policy for business travel expenses?\n",
      "[Orchestrator] Classified as: Finance (confidence: 0.95)\n",
      "[Orchestrator] Reasoning: The query is related to expenses and reimbursement policies, which falls under the Finance department's area of expertise.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CLASSIFICATION:\n",
      "  Department: Finance\n",
      "  Confidence: 0.95\n",
      "  Reasoning: The query is related to expenses and reimbursement policies, which falls under the Finance department's area of expertise.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ANSWER:\n",
      "The reimbursement policy for business travel expenses includes the following eligible expenses when properly documented and approved:\n",
      "- Airfare for business trips (economy class)\n",
      "- Hotel accommodations at reasonable rates\n",
      "- Ground transportation (rental cars, taxis, ride-sharing, parking)\n",
      "- Mileage reimbursement for personal vehicle use at IRS standard rate\n",
      "- Meals during business travel (within per diem limits)\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = \"What is the reimbursement policy for business travel expenses?\"\n",
    "result3 = orchestrator.process_query(query3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: IT Query - VPN Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROCESSING QUERY: I forgot my VPN password. How can I reset it?\n",
      "================================================================================\n",
      "\n",
      "[Orchestrator] Classifying query: I forgot my VPN password. How can I reset it?\n",
      "[Orchestrator] Classified as: IT (confidence: 0.95)\n",
      "[Orchestrator] Reasoning: The query is related to a technical issue with VPN password, which falls under IT department's expertise.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CLASSIFICATION:\n",
      "  Department: IT\n",
      "  Confidence: 0.95\n",
      "  Reasoning: The query is related to a technical issue with VPN password, which falls under IT department's expertise.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ANSWER:\n",
      "If you have forgotten your VPN password, you can reset it by following these steps:\n",
      "\n",
      "1. Call IT Support at Extension 4357 to initiate the password reset process.\n",
      "2. Verify your identity with your employee ID and birth date.\n",
      "3. A temporary password will be provided to you via your registered phone number.\n",
      "4. Log in to the VPN using the temporary password.\n",
      "5. You will be prompted to change the temporary password upon first login.\n",
      "\n",
      "If you encounter any issues during the password reset process, please contact IT Support for further assistance.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query4 = \"I forgot my VPN password. How can I reset it?\"\n",
    "result4 = orchestrator.process_query(query4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Response Quality Evaluation (BONUS)\n",
    "\n",
    "Now let's evaluate the quality of our responses using the Evaluator Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATING RESPONSE QUALITY\n",
      "================================================================================\n",
      "Using trace_id: 9a0a40865a8458f9...\n",
      "\n",
      "[Evaluator] Evaluating response for query: How many PTO days do I get per year?...\n",
      "[Evaluator] Overall Score: 9/10\n",
      "[Evaluator] Relevance: 10/10\n",
      "[Evaluator] Completeness: 9/10\n",
      "[Evaluator] Accuracy: 9/10\n",
      "[Evaluator] Clarity: 9/10\n",
      "[Evaluator] Scores logged to Langfuse (trace_id: 9a0a40865a8458f98c884552dfac52a2)\n",
      "\n",
      "üìä Evaluation Results:\n",
      "   Overall Score: 9/10\n",
      "   Relevance: 10/10\n",
      "   Completeness: 9/10\n",
      "   Accuracy: 9/10\n",
      "   Clarity: 9/10\n",
      "\n",
      "üí¨ Feedback: The response is highly relevant, providing a detailed breakdown of PTO accrual based on years of service for full-time employees and a general guideline for part-time employees. The information is comprehensive and accurate, addressing the user's question effectively. The clarity of the response is good, but it could be improved by organizing the information into bullet points for better readability.\n",
      "\n",
      "‚úÖ Strengths: 1. Highly relevant information provided based on the user's question. 2. Detailed breakdown of PTO accrual based on years of service for full-time employees. 3. Clear guidance on how part-time employees accrue PTO. 4. Suggested contacting HR for personalized inquiries.\n",
      "\n",
      "üîß Improvements: 1. Organize the information into bullet points for easier readability. 2. Consider providing a brief summary at the beginning of the response before diving into specific details.\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Scores logged to Langfuse with trace_id!\n",
      "üîó Check 'Scores' tab at: https://cloud.langfuse.com\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the first query result\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING RESPONSE QUALITY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get trace_id from result if available\n",
    "trace_id = result1.get('trace_id')\n",
    "if trace_id:\n",
    "    print(f\"Using trace_id: {trace_id[:16]}...\")\n",
    "\n",
    "evaluation1 = evaluator.evaluate_response(\n",
    "    query=result1[\"query\"],\n",
    "    answer=result1[\"answer\"],\n",
    "    department=result1[\"classification\"][\"department\"],\n",
    "    source_documents=result1[\"source_documents\"],\n",
    "    trace_id=trace_id  # Pass trace_id to link scores to trace\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Evaluation Results:\")\n",
    "print(f\"   Overall Score: {evaluation1.overall_score}/10\")\n",
    "print(f\"   Relevance: {evaluation1.relevance_score}/10\")\n",
    "print(f\"   Completeness: {evaluation1.completeness_score}/10\")\n",
    "print(f\"   Accuracy: {evaluation1.accuracy_score}/10\")\n",
    "print(f\"   Clarity: {evaluation1.clarity_score}/10\")\n",
    "print(f\"\\nüí¨ Feedback: {evaluation1.feedback}\")\n",
    "print(f\"\\n‚úÖ Strengths: {evaluation1.strengths}\")\n",
    "print(f\"\\nüîß Improvements: {evaluation1.improvements}\")\n",
    "\n",
    "if trace_id:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ Scores logged to Langfuse with trace_id!\")\n",
    "    print(\"üîó Check 'Scores' tab at: https://cloud.langfuse.com\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Testing with Test Queries\n",
    "\n",
    "Let's test the system with all queries from our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Loaded 15 test queries\n",
      "\n",
      "Test queries by department:\n",
      "   HR: 5 queries\n",
      "   IT: 5 queries\n",
      "   Finance: 5 queries\n"
     ]
    }
   ],
   "source": [
    "# Load test queries\n",
    "with open('test_queries.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"üìù Loaded {len(test_data['test_queries'])} test queries\")\n",
    "print(\"\\nTest queries by department:\")\n",
    "\n",
    "dept_counts = {}\n",
    "for test in test_data['test_queries']:\n",
    "    dept = test['expected_department']\n",
    "    dept_counts[dept] = dept_counts.get(dept, 0) + 1\n",
    "\n",
    "for dept, count in dept_counts.items():\n",
    "    print(f\"   {dept}: {count} queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RUNNING BATCH TESTS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "[1/15] Testing: How many PTO days do I get per year?...\n",
      "\n",
      "[Orchestrator] Classifying query: How many PTO days do I get per year?\n",
      "[Orchestrator] Classified as: HR (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to employee benefits and leave policies, which fall under the HR department's responsibilities.\n",
      "   Expected: HR | Got: HR | ‚úÖ CORRECT\n",
      "   Confidence: 0.90\n",
      "\n",
      "[2/15] Testing: My laptop won't turn on, what should I do?...\n",
      "\n",
      "[Orchestrator] Classifying query: My laptop won't turn on, what should I do?\n",
      "[Orchestrator] Classified as: IT (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to hardware troubleshooting, which falls under the IT department's expertise.\n",
      "   Expected: IT | Got: IT | ‚úÖ CORRECT\n",
      "   Confidence: 0.90\n",
      "\n",
      "[3/15] Testing: What is the reimbursement policy for business travel expense...\n",
      "\n",
      "[Orchestrator] Classifying query: What is the reimbursement policy for business travel expenses?\n",
      "[Orchestrator] Classified as: Finance (confidence: 0.95)\n",
      "[Orchestrator] Reasoning: The query is related to expenses and reimbursement policies, which falls under the Finance department's area of expertise.\n",
      "   Expected: Finance | Got: Finance | ‚úÖ CORRECT\n",
      "   Confidence: 0.95\n",
      "\n",
      "[4/15] Testing: I forgot my VPN password. How can I reset it?...\n",
      "\n",
      "[Orchestrator] Classifying query: I forgot my VPN password. How can I reset it?\n",
      "[Orchestrator] Classified as: IT (confidence: 0.95)\n",
      "[Orchestrator] Reasoning: The query is related to a technical issue with VPN password, which falls under IT department's expertise.\n",
      "   Expected: IT | Got: IT | ‚úÖ CORRECT\n",
      "   Confidence: 0.95\n",
      "\n",
      "[5/15] Testing: What benefits does the company offer for new employees?...\n",
      "\n",
      "[Orchestrator] Classifying query: What benefits does the company offer for new employees?\n",
      "[Orchestrator] Classified as: HR (confidence: 0.95)\n",
      "[Orchestrator] Reasoning: The query is related to employee benefits which falls under HR department's responsibilities.\n",
      "   Expected: HR | Got: HR | ‚úÖ CORRECT\n",
      "   Confidence: 0.95\n",
      "\n",
      "[6/15] Testing: How do I submit an invoice for payment?...\n",
      "\n",
      "[Orchestrator] Classifying query: How do I submit an invoice for payment?\n",
      "[Orchestrator] Classified as: Finance (confidence: 0.95)\n",
      "[Orchestrator] Reasoning: The query is related to submitting an invoice for payment, which falls under the Finance department's responsibilities.\n",
      "   Expected: Finance | Got: Finance | ‚úÖ CORRECT\n",
      "   Confidence: 0.95\n",
      "\n",
      "[7/15] Testing: Can I work from home 3 days a week?...\n",
      "\n",
      "[Orchestrator] Classifying query: Can I work from home 3 days a week?\n",
      "[Orchestrator] Classified as: HR (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: This query is related to remote work policies, which falls under the HR department's responsibilities.\n",
      "   Expected: HR | Got: HR | ‚úÖ CORRECT\n",
      "   Confidence: 0.90\n",
      "\n",
      "[8/15] Testing: My Outlook email is not syncing properly...\n",
      "\n",
      "[Orchestrator] Classifying query: My Outlook email is not syncing properly\n",
      "[Orchestrator] Classified as: IT (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to email syncing issue, which falls under IT department's expertise.\n",
      "   Expected: IT | Got: IT | ‚úÖ CORRECT\n",
      "   Confidence: 0.90\n",
      "\n",
      "[9/15] Testing: What is the approval process for capital expenditures over $...\n",
      "\n",
      "[Orchestrator] Classifying query: What is the approval process for capital expenditures over $10,000?\n",
      "[Orchestrator] Classified as: Finance (confidence: 0.95)\n",
      "[Orchestrator] Reasoning: The query is related to financial policies and specifically about the approval process for capital expenditures, which falls under the Finance department's area of expertise.\n",
      "   Expected: Finance | Got: Finance | ‚úÖ CORRECT\n",
      "   Confidence: 0.95\n",
      "\n",
      "[10/15] Testing: How do I connect to the office WiFi network?...\n",
      "\n",
      "[Orchestrator] Classifying query: How do I connect to the office WiFi network?\n",
      "[Orchestrator] Classified as: IT (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to network connectivity and setting up a device to connect to the office WiFi network, which falls under IT support.\n",
      "   Expected: IT | Got: IT | ‚úÖ CORRECT\n",
      "   Confidence: 0.90\n",
      "\n",
      "[11/15] Testing: What is the parental leave policy?...\n",
      "\n",
      "[Orchestrator] Classifying query: What is the parental leave policy?\n",
      "[Orchestrator] Classified as: HR (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to employee benefits and leave policies, which fall under the HR department's responsibilities.\n",
      "   Expected: HR | Got: HR | ‚úÖ CORRECT\n",
      "   Confidence: 0.90\n",
      "\n",
      "[12/15] Testing: When will I receive reimbursement for my expense report?...\n",
      "\n",
      "[Orchestrator] Classifying query: When will I receive reimbursement for my expense report?\n",
      "[Orchestrator] Classified as: Finance (confidence: 0.95)\n",
      "[Orchestrator] Reasoning: The query is related to reimbursement for expenses, which falls under the Finance department's responsibilities.\n",
      "   Expected: Finance | Got: Finance | ‚úÖ CORRECT\n",
      "   Confidence: 0.95\n",
      "\n",
      "[13/15] Testing: How do I set up two-factor authentication?...\n",
      "\n",
      "[Orchestrator] Classifying query: How do I set up two-factor authentication?\n",
      "[Orchestrator] Classified as: IT (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to setting up a security feature, which falls under IT's domain.\n",
      "   Expected: IT | Got: IT | ‚úÖ CORRECT\n",
      "   Confidence: 0.90\n",
      "\n",
      "[14/15] Testing: What professional development budget is available to employe...\n",
      "\n",
      "[Orchestrator] Classifying query: What professional development budget is available to employees?\n",
      "[Orchestrator] Classified as: HR (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to professional development budget for employees, which falls under HR department's responsibilities.\n",
      "   Expected: HR | Got: HR | ‚úÖ CORRECT\n",
      "   Confidence: 0.90\n",
      "\n",
      "[15/15] Testing: What is the company's fiscal year and budget planning timeli...\n",
      "\n",
      "[Orchestrator] Classifying query: What is the company's fiscal year and budget planning timeline?\n",
      "[Orchestrator] Classified as: Finance (confidence: 0.95)\n",
      "[Orchestrator] Reasoning: The query is related to fiscal year, budget planning, and financial timelines, which fall under the Finance department's expertise.\n",
      "   Expected: Finance | Got: Finance | ‚úÖ CORRECT\n",
      "   Confidence: 0.95\n",
      "\n",
      "================================================================================\n",
      "BATCH TEST RESULTS\n",
      "================================================================================\n",
      "\n",
      "üìä Overall Accuracy: 100.0% (15/15)\n",
      "\n",
      "‚úÖ Correct Classifications: 15\n",
      "‚ùå Incorrect Classifications: 0\n"
     ]
    }
   ],
   "source": [
    "# Run all test queries\n",
    "results = []\n",
    "correct_classifications = 0\n",
    "total_queries = len(test_data['test_queries'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING BATCH TESTS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for i, test in enumerate(test_data['test_queries'], 1):\n",
    "    print(f\"\\n[{i}/{total_queries}] Testing: {test['query'][:60]}...\")\n",
    "    \n",
    "    # Process query\n",
    "    result = orchestrator.process_query(test['query'], verbose=False)\n",
    "    \n",
    "    # Check if classification is correct\n",
    "    expected = test['expected_department']\n",
    "    actual = result['classification']['department']\n",
    "    is_correct = expected == actual\n",
    "    \n",
    "    if is_correct:\n",
    "        correct_classifications += 1\n",
    "        status = \"‚úÖ CORRECT\"\n",
    "    else:\n",
    "        status = \"‚ùå INCORRECT\"\n",
    "    \n",
    "    print(f\"   Expected: {expected} | Got: {actual} | {status}\")\n",
    "    print(f\"   Confidence: {result['classification']['confidence']:.2f}\")\n",
    "    \n",
    "    results.append({\n",
    "        'query': test['query'],\n",
    "        'expected': expected,\n",
    "        'actual': actual,\n",
    "        'correct': is_correct,\n",
    "        'confidence': result['classification']['confidence'],\n",
    "        'answer': result['answer']\n",
    "    })\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (correct_classifications / total_queries) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH TEST RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Overall Accuracy: {accuracy:.1f}% ({correct_classifications}/{total_queries})\")\n",
    "print(f\"\\n‚úÖ Correct Classifications: {correct_classifications}\")\n",
    "print(f\"‚ùå Incorrect Classifications: {total_queries - correct_classifications}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate All Responses (BONUS)\n",
    "\n",
    "Let's evaluate the quality of all responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATING RESPONSE QUALITY (First 5 queries)\n",
      "================================================================================\n",
      "\n",
      "[1/5] Evaluating: How many PTO days do I get per year?...\n",
      "\n",
      "[Orchestrator] Classifying query: How many PTO days do I get per year?\n",
      "[Orchestrator] Classified as: HR (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to employee benefits and leave policies, which fall under the HR department's responsibilities.\n",
      "\n",
      "[Evaluator] Evaluating response for query: How many PTO days do I get per year?...\n",
      "[Evaluator] Overall Score: 9/10\n",
      "[Evaluator] Relevance: 10/10\n",
      "[Evaluator] Completeness: 9/10\n",
      "[Evaluator] Accuracy: 9/10\n",
      "[Evaluator] Clarity: 9/10\n",
      "[Evaluator] Scores logged to Langfuse (trace_id: 925a187ad3dc7a2fb30c8662c96b3a56)\n",
      "   Overall: 9/10\n",
      "   Relevance: 10/10 | Completeness: 9/10\n",
      "   Accuracy: 9/10 | Clarity: 9/10\n",
      "   Trace ID: 925a187ad3dc7a2f... ‚úì\n",
      "\n",
      "[2/5] Evaluating: My laptop won't turn on, what should I do?...\n",
      "\n",
      "[Orchestrator] Classifying query: My laptop won't turn on, what should I do?\n",
      "[Orchestrator] Classified as: IT (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to hardware troubleshooting, which falls under the IT department's expertise.\n",
      "\n",
      "[Evaluator] Evaluating response for query: My laptop won't turn on, what should I do?...\n",
      "[Evaluator] Overall Score: 9/10\n",
      "[Evaluator] Relevance: 9/10\n",
      "[Evaluator] Completeness: 8/10\n",
      "[Evaluator] Accuracy: 9/10\n",
      "[Evaluator] Clarity: 9/10\n",
      "[Evaluator] Scores logged to Langfuse (trace_id: a6919a6b169e2fc70fc755dc9d4dae26)\n",
      "   Overall: 9/10\n",
      "   Relevance: 9/10 | Completeness: 8/10\n",
      "   Accuracy: 9/10 | Clarity: 9/10\n",
      "   Trace ID: a6919a6b169e2fc7... ‚úì\n",
      "\n",
      "[3/5] Evaluating: What is the reimbursement policy for business travel expense...\n",
      "\n",
      "[Orchestrator] Classifying query: What is the reimbursement policy for business travel expenses?\n",
      "[Orchestrator] Classified as: Finance (confidence: 0.95)\n",
      "[Orchestrator] Reasoning: The query is related to expenses and reimbursement policies, which falls under the Finance department's area of expertise.\n",
      "\n",
      "[Evaluator] Evaluating response for query: What is the reimbursement policy for business trav...\n",
      "[Evaluator] Overall Score: 9/10\n",
      "[Evaluator] Relevance: 9/10\n",
      "[Evaluator] Completeness: 9/10\n",
      "[Evaluator] Accuracy: 9/10\n",
      "[Evaluator] Clarity: 9/10\n",
      "[Evaluator] Scores logged to Langfuse (trace_id: 28dc4bae745f87f42eea567e500784a4)\n",
      "   Overall: 9/10\n",
      "   Relevance: 9/10 | Completeness: 9/10\n",
      "   Accuracy: 9/10 | Clarity: 9/10\n",
      "   Trace ID: 28dc4bae745f87f4... ‚úì\n",
      "\n",
      "[4/5] Evaluating: I forgot my VPN password. How can I reset it?...\n",
      "\n",
      "[Orchestrator] Classifying query: I forgot my VPN password. How can I reset it?\n",
      "[Orchestrator] Classified as: IT (confidence: 0.90)\n",
      "[Orchestrator] Reasoning: The query is related to a technical issue with VPN password, which falls under IT department's expertise.\n",
      "\n",
      "[Evaluator] Evaluating response for query: I forgot my VPN password. How can I reset it?...\n",
      "[Evaluator] Overall Score: 9/10\n",
      "[Evaluator] Relevance: 9/10\n",
      "[Evaluator] Completeness: 9/10\n",
      "[Evaluator] Accuracy: 9/10\n",
      "[Evaluator] Clarity: 9/10\n",
      "[Evaluator] Scores logged to Langfuse (trace_id: ba11f202d3164d858cad62b44cd4e42e)\n",
      "   Overall: 9/10\n",
      "   Relevance: 9/10 | Completeness: 9/10\n",
      "   Accuracy: 9/10 | Clarity: 9/10\n",
      "   Trace ID: ba11f202d3164d85... ‚úì\n",
      "\n",
      "[5/5] Evaluating: What benefits does the company offer for new employees?...\n",
      "\n",
      "[Orchestrator] Classifying query: What benefits does the company offer for new employees?\n",
      "[Orchestrator] Classified as: HR (confidence: 0.95)\n",
      "[Orchestrator] Reasoning: The query is related to employee benefits which falls under HR department's responsibilities.\n",
      "\n",
      "[Evaluator] Evaluating response for query: What benefits does the company offer for new emplo...\n",
      "[Evaluator] Overall Score: 9/10\n",
      "[Evaluator] Relevance: 9/10\n",
      "[Evaluator] Completeness: 9/10\n",
      "[Evaluator] Accuracy: 9/10\n",
      "[Evaluator] Clarity: 9/10\n",
      "[Evaluator] Scores logged to Langfuse (trace_id: 124522738de642181cb32ce495ed800e)\n",
      "   Overall: 9/10\n",
      "   Relevance: 9/10 | Completeness: 9/10\n",
      "   Accuracy: 9/10 | Clarity: 9/10\n",
      "   Trace ID: 124522738de64218... ‚úì\n",
      "\n",
      "================================================================================\n",
      "AVERAGE QUALITY SCORES\n",
      "================================================================================\n",
      "\n",
      "üìä Overall Average: 9.0/10\n",
      "   Relevance: 9.2/10\n",
      "   Completeness: 8.8/10\n",
      "   Accuracy: 9.0/10\n",
      "   Clarity: 9.0/10\n",
      "\n",
      "================================================================================\n",
      "‚úÖ All scores logged to Langfuse with trace IDs!\n",
      "üìä View scores at: https://cloud.langfuse.com\n",
      "   Navigate to: Scores tab\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate quality of first 5 responses\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING RESPONSE QUALITY (First 5 queries)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "evaluation_results = []\n",
    "avg_scores = {\n",
    "    'overall': 0,\n",
    "    'relevance': 0,\n",
    "    'completeness': 0,\n",
    "    'accuracy': 0,\n",
    "    'clarity': 0\n",
    "}\n",
    "\n",
    "for i, test in enumerate(test_data['test_queries'][:5], 1):\n",
    "    print(f\"\\n[{i}/5] Evaluating: {test['query'][:60]}...\")\n",
    "    \n",
    "    # Get fresh result\n",
    "    result = orchestrator.process_query(test['query'], verbose=False)\n",
    "    \n",
    "    # Get trace_id from result\n",
    "    trace_id = result.get('trace_id')\n",
    "    \n",
    "    # Evaluate - will automatically log to Langfuse with trace_id\n",
    "    evaluation = evaluator.evaluate_response(\n",
    "        query=result[\"query\"],\n",
    "        answer=result[\"answer\"],\n",
    "        department=result[\"classification\"][\"department\"],\n",
    "        source_documents=result[\"source_documents\"],\n",
    "        trace_id=trace_id  # Pass trace_id to link scores\n",
    "    )\n",
    "    \n",
    "    print(f\"   Overall: {evaluation.overall_score}/10\")\n",
    "    print(f\"   Relevance: {evaluation.relevance_score}/10 | Completeness: {evaluation.completeness_score}/10\")\n",
    "    print(f\"   Accuracy: {evaluation.accuracy_score}/10 | Clarity: {evaluation.clarity_score}/10\")\n",
    "    if trace_id:\n",
    "        print(f\"   Trace ID: {trace_id[:16]}... ‚úì\")\n",
    "    \n",
    "    # Accumulate scores\n",
    "    avg_scores['overall'] += evaluation.overall_score\n",
    "    avg_scores['relevance'] += evaluation.relevance_score\n",
    "    avg_scores['completeness'] += evaluation.completeness_score\n",
    "    avg_scores['accuracy'] += evaluation.accuracy_score\n",
    "    avg_scores['clarity'] += evaluation.clarity_score\n",
    "    \n",
    "    evaluation_results.append(evaluation)\n",
    "\n",
    "# Calculate averages\n",
    "n = len(evaluation_results)\n",
    "for key in avg_scores:\n",
    "    avg_scores[key] /= n\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVERAGE QUALITY SCORES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Overall Average: {avg_scores['overall']:.1f}/10\")\n",
    "print(f\"   Relevance: {avg_scores['relevance']:.1f}/10\")\n",
    "print(f\"   Completeness: {avg_scores['completeness']:.1f}/10\")\n",
    "print(f\"   Accuracy: {avg_scores['accuracy']:.1f}/10\")\n",
    "print(f\"   Clarity: {avg_scores['clarity']:.1f}/10\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ All scores logged to Langfuse with trace IDs!\")\n",
    "print(\"üìä View scores at: https://cloud.langfuse.com\")\n",
    "print(\"   Navigate to: Scores tab\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interactive Testing\n",
    "\n",
    "Try your own queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive query testing\n",
    "def test_query(query_text):\n",
    "    \"\"\"\n",
    "    Test a custom query and evaluate the response.\n",
    "    \n",
    "    Args:\n",
    "        query_text: Your question to test\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    result = orchestrator.process_query(query_text, verbose=True)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"EVALUATING RESPONSE QUALITY\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Get trace_id from result\n",
    "    trace_id = result.get('trace_id')\n",
    "    \n",
    "    evaluation = evaluator.evaluate_response(\n",
    "        query=result[\"query\"],\n",
    "        answer=result[\"answer\"],\n",
    "        department=result[\"classification\"][\"department\"],\n",
    "        source_documents=result[\"source_documents\"],\n",
    "        trace_id=trace_id  # Pass trace_id to link scores\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä Quality Scores:\")\n",
    "    print(f\"   Overall: {evaluation.overall_score}/10\")\n",
    "    print(f\"   Relevance: {evaluation.relevance_score}/10\")\n",
    "    print(f\"   Completeness: {evaluation.completeness_score}/10\")\n",
    "    print(f\"   Accuracy: {evaluation.accuracy_score}/10\")\n",
    "    print(f\"   Clarity: {evaluation.clarity_score}/10\")\n",
    "    print(f\"\\nüí¨ {evaluation.feedback}\")\n",
    "    \n",
    "    if trace_id:\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(f\"‚úÖ Scores logged to Langfuse (trace_id: {trace_id[:16]}...)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return result, evaluation\n",
    "\n",
    "# Example usage - uncomment to try your own!\n",
    "# test_query(\"What is the parental leave policy?\")\n",
    "# test_query(\"How do I connect to the office WiFi?\")\n",
    "# test_query(\"When will I receive my expense reimbursement?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. View Results in Langfuse\n",
    "\n",
    "All queries have been traced and logged to Langfuse. You can now:\n",
    "\n",
    "1. Visit [cloud.langfuse.com](https://cloud.langfuse.com)\n",
    "2. Navigate to your project\n",
    "3. View **Traces** to see all query processing steps\n",
    "4. View **Scores** to see quality evaluations\n",
    "5. Debug any misclassifications or poor responses\n",
    "\n",
    "### What You Can See in Langfuse:\n",
    "\n",
    "**Traces:**\n",
    "- Complete execution path for each query\n",
    "- Classification reasoning\n",
    "- Retrieved documents\n",
    "- Generated responses\n",
    "- Execution time and token usage\n",
    "\n",
    "**Scores:**\n",
    "- Overall quality scores (1-10)\n",
    "- Dimension-specific scores (relevance, completeness, accuracy, clarity)\n",
    "- Detailed feedback and suggestions\n",
    "\n",
    "**Analytics:**\n",
    "- Query volume by department\n",
    "- Average response quality\n",
    "- Most common query types\n",
    "- Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary & Next Steps\n",
    "\n",
    "### What We've Built:\n",
    "\n",
    "‚úÖ **Multi-Agent System**: Orchestrator + 3 specialized RAG agents (HR, IT, Finance)\n",
    "\n",
    "‚úÖ **Intent Classification**: Automatic query routing with confidence scores\n",
    "\n",
    "‚úÖ **RAG Implementation**: Document retrieval with 50+ chunks per domain\n",
    "\n",
    "‚úÖ **Langfuse Integration**: Complete observability and tracing\n",
    "\n",
    "‚úÖ **Quality Evaluation**: Automated response scoring (BONUS)\n",
    "\n",
    "### Technical Highlights:\n",
    "\n",
    "- **LangChain Framework**: Production-grade components\n",
    "- **Vector Stores**: ChromaDB for efficient retrieval\n",
    "- **Structured Outputs**: Pydantic models for type safety\n",
    "- **Observability**: Full tracing with Langfuse\n",
    "- **Quality Metrics**: Multi-dimensional evaluation\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Review Langfuse Dashboard**: Analyze traces and scores\n",
    "2. **Test Edge Cases**: Try ambiguous or multi-department queries\n",
    "3. **Tune Parameters**: Adjust chunk size, k-value, temperature\n",
    "4. **Add More Departments**: Legal, Sales, Marketing\n",
    "5. **Deploy to Production**: API wrapper, web interface\n",
    "\n",
    "### Performance Expectations:\n",
    "\n",
    "- **Classification Accuracy**: 90%+ expected\n",
    "- **Response Quality**: 7-9/10 average\n",
    "- **Latency**: 2-5 seconds per query\n",
    "- **Cost**: ~$0.01-0.05 per query\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations! You've built a production-grade multi-agent system with full observability!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Flushing all data to Langfuse...\n",
      "‚úÖ All data sent to Langfuse!\n",
      "\n",
      "================================================================================\n",
      "üìä VIEW YOUR RESULTS IN LANGFUSE\n",
      "================================================================================\n",
      "\n",
      "1. Go to: https://cloud.langfuse.com\n",
      "2. Navigate to your project\n",
      "3. Click on 'Traces' tab to see all query executions\n",
      "4. Click on 'Scores' tab to see all evaluation scores\n",
      "\n",
      "You should see:\n",
      "  - Query traces (RetrievalQA, ChatOpenAI)\n",
      "  - Evaluation traces with scores\n",
      "  - Score names: overall_quality, relevance, completeness, accuracy, clarity\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Ensure all data is sent to Langfuse\n",
    "print(\"üîÑ Flushing all data to Langfuse...\")\n",
    "langfuse.flush()\n",
    "print(\"‚úÖ All data sent to Langfuse!\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä VIEW YOUR RESULTS IN LANGFUSE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. Go to: https://cloud.langfuse.com\")\n",
    "print(\"2. Navigate to your project\")\n",
    "print(\"3. Click on 'Traces' tab to see all query executions\")\n",
    "print(\"4. Click on 'Scores' tab to see all evaluation scores\")\n",
    "print(\"\\nYou should see:\")\n",
    "print(\"  - Query traces (RetrievalQA, ChatOpenAI)\")\n",
    "print(\"  - Evaluation traces with scores\")\n",
    "print(\"  - Score names: overall_quality, relevance, completeness, accuracy, clarity\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3-multiagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
